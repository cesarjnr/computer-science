Notação Big O

A notação Big O é uma notação utilizada para descrever a complexidade (eficiência) de um algoritmo no melhor e, mais comumente, no pior cenário. Esse cenário é representado pelo tamanho da entrada de um algoritmo. Ela é representada da seguinte forma:

	O(n)
	
O significa ordem de magnitude de complexidade. n é o tamanho da entrada.
Esse "tamanho da entrada" que nos referimos vai depender do tipo de problema que estamos resolvendo com o algoritmo. Em um algoritmo de busca, por exemplo, se precisamos encontrar um valor em uma lista que contém, digamos, 16 valores no total, então o tamanho da entrada será 16.

notacao-big-o image here

É importante lembrar que a complexidade é relativa. Isto é, quando avaliamos a complexidade de um algoritmo, fazemos isso comparando-o com outro algoritmo que resolve o mesmo problema e não com todos os algoritmos existentes. Por exemplo, quando avaliamos a complexidade de um algoritmo de busca binária, podemos compará-lo com o algoritmo de busca linear e sabermos qual é o mais eficiente.

Notações Mais Comuns

O(1)

Também conhecido como tempo constante, essa notação indica que nosso algoritmo tem uma complexidade constante. Ou seja, independente do tamanho do valor de entrada, a quantidade de operações que o algoritmo necessitará para ser concluído será a mesma.
Uma operação conhecida que possui essa complexidade é a busca de um valor em uma lista através de seu índice. Independente do tamanho da lista, o algoritmo sabe exatamente onde o valor se encontra e vai direto nele para buscá-lo.

O(log n)

Também conhecido como tempo logarítmico, essa notação indica que a cada vez que o tamanho do valor de entrada dobra, a quantidade de operações necessárias para concluir o algoritmo aumenta apenas em 1.
Um algoritmo conhecido que possui essa complexidade para seu pior cenário é a busca binária. Se temos uma lista que contém 10 valores o pior cenário é 4 comparações. Se a lista aumenta para 20 valores o pior cenário é 5 comparações. Se aumenta para 40 o pior cenário é 6 comparações. E assim sucessivamente conforme a quantidade de valores dobra.

Observação: Também pode vir na forma O(ln n).

---> Logaritmo

Na notação O(log n) que vimos anteriormente, existe uma relação matemática para o trecho log n. Chamamos essa relação de logaritmo de n.
Na matemática, o logaritmo é o inverso do expoente de um número. Vamos começar pelo básico:

	2 ^ 1 = 2 x 1 = 2
	2 ^ 2 = 2 x 2 = 4
	2 ^ 3 = 2 x 2 x 2 = 8
	
Como sabemos, na potência, o valor que a base está elevada é chamado de expoente. Nos exemplos acima, a base é 2 e os expoentes são 1, 2 e 3. Em outras palavras, na potência 2 ^ 1 estamos multiplicando o 2 apenas 1 vez, na potência 2 ^ 2 estamos multiplicando o 2 duas vezes e na potência 2 ^ 3 estamos multiplicando o 2 três vezes.
Agora, veja este exemplo de logaritmo:

	log 8 = 3
	   2

Lê-se log de 8 na base 2, onde 2 é chamado de base, 8 é chamado de logaritmando e 3 é chamado de logaritmo.
O que estamos informando com o logaritmo é basicamente o oposto de uma potência. Enquanto a potência nos diz, com o expoente, quantas vezes precisamos multiplicar a base para encontrar o resultado, o logaritmo nos diz quantas vezes precisamos dividir o logaritmando pela base para obter o valor 1. Na potência 2 ^ 3 = 8 estamos dizendo que é necessário multiplicar o 2 três vezes para encontrar o 8. No logaritmo log 8 = 3 estamos dizendo que é necessário dividir o 8 por 2 três vezes para obter o valor 1.
																	         2																	    
Trazendo o logaritmo para nosso exemplo de busca binária, imagine uma lista contendo 16 valores:

notacao-big-o-02 image here

Como a busca binária tem complexidade O(log n) e nosso pior cenário é 16, temos O(log 16). Como o logaritmo de 16 na base 2 resulta em 4, isso quer dizer que no pior cenário (com o valor a ser encontrado estando no primeiro ou no último índice da lista) haverá 4 comparações entre o valor atual e o valor que está sendo buscado.
													        
Observaçao: Na notação big O não precisamos informar a base pois ela sempre será 2.

O(n)

Também conhecido como tempo linear, essa notação indica que o algoritmo tem uma complexidade linear. Ou seja, para cada incremento no valor de entrada temos uma operação adicional.
Um algoritmo conhecido que possui essa complexidade para seu pior cenário é a busca linear. Se temos uma lista que contém apenas 1 valor o algoritmo precisa realizar apenas uma comparação. Se a lista aumenta para 2 o pior cenário é 2 comparações. Se aumenta para 3 o pior cenário 3 comparações. E assim sucessivamente conforme a lista cresce.

O(n²)

Também conhecido como tempo quadrático, essa notação indica que a cada vez que o tamanho do valor de entrada aumenta em 1, a quantidade de operações necessárias para concluir o algoritmo cresce de maneira quadrática. No pior cenário, a quantidade de operações necessárias para o agoritmo ser concluído será igua ao quadrado do tamanho de entrada.
Um algoritmo conhecido que possui essa complexidade para seu pior cenário é o algoritmo de ordenação bubble sort. Veremos em detalhes mais a frente este algoritmo mas ele basicamente consiste em percorrer a lista comparando o valor que está sendo iterado no momento com o valor a sua direita na lista. Ele percorre a lista inteira para cada valor individual da lista.

O(n log n)

Também conhecido como tempo quase-linear, essa notação indica que a cada vez que o tamanho do valor de entrada aumenta, serão executadas log n operações.
Um algoritmo conhecido que possui essa complexidade para seu pior cenário é o algoritmo de ordenação chamado merge sort. Veremos em detalhes mais a frente este algoritmo mas ele basicamente consiste começar separando a lista em 2 sub-listas e, posteriormente, dividir as sub-listas geradas em 2 novamente até que todas as sub-listas geradas contenha apenas 1 valor. Ao final desse processo, ele começa a juntar essas sub-listas novamente de maneira já ordenada comparando os valores de cada uma delas. Veremos mais a frente quando formos estudar o merge sort como essas comparações ocorrem mas o fato das sub-divisões acontecerem faz com que os valores sejam comparados uns com os outros apenas uma única vez. Dessa maneira, a etapa inicial de dividir a lista pela metade a todo momento faz com que tenhamos a complexidade O(log n) como já vimos anteriormente no algoritmo de busca binária. E a segunda parte de fazer as comparações e juntar as sub-listas tem a complexidade O(n), resultando na complexidade O(n log n).

O(x^n)

Algumas complexidades que vimos até o momento são complexidades com tempos de execução conhecidos como tempo polinominal, isto é, para um dado valor de n, seu pior cenário está na forma de n elevado a k onde k é algum valor como 2 (tempo quadrático) ou 3 (tempo cúbico). Esses algoritmos com tempo polinomial são algoritmos considerados como eficientes e são prováveis de serem usados na prática.
Agora veremos o outro lado da moeda, ou seja, veremos complexidades com tempos de execução considerados ineficientes. Esses tempos são conhecidos como tempo exponencial. Nesses tempos de execução, se o valor de n mudar levemente, o número de operações necessárias para o pior caso cresce de forma exponencial. Vamos a um exemplo:

exponential-time-complexity image here

Imagine que temos um cadeado onde é necessária uma combinação correta de 2 dígitos para abri-lo e que os dígitos possíveis são os que estão no range de 0 a 9. Teríamos que partir do 00 e ir incrementando de 1 em 1 o segundo dígito até atingir o dígito 9. Depois, incrementaríamos o primeiro dígito em 1, voltaríamos o segundo dígito para 0 e íriamos incrementando de 1 em 1 novamente até chegar no 9. Ou seja, no pior cenário possível, a combinação seria 99.
A razão para esse tipo de algoritmo ser tão ineficiente é que com um pequeno incremento no valor de entrada, o número de operações cresce significativamente:

exponentual-time-complexity-02 image here

Como podemos ver, adicionando mais um dígito ao cadeado, o número de operações necessárias para o caso da combinação ser o pior caso (999) aumentaria drasticamente.

O(!n)

Também na classe das complexidas com tempo exponencial, essa notação é conhecida como tempo fatorial e indica que a quantidade de operações necessárias para a conclusão de um algoritmo aumenta de maneira fatorial conforme o valor de entrada. Vamos a um exemplo:

exponential-time-complexity-03 image here

Na imagem acima temos o problema conhecido como "Problema do Caixeiro Viajante" que tenta determinar a menor rota para percorrer uma série de cidades, retornando à cidade de origem. No exemplo acima, é preciso realizar todas as combinações possíveis entre os 3 pontos para determinar a menor rota. Em problemas como esse onde é preciso realizar uma análise combinatória, uma das ferramentas mais utilizadas é a fatorial e por isso que utilizamos a notação de fatorial (!n) para esse tipo de complexidade. Sendo assim, tendo 3 possíveis valores, teríamos o seguinte:

	o(!3) = 3x2x1 = 6
	
Ou seja, o número máximo de combinações (operações) desse algoritmo seria 6.

exponential-time-complexity-04 image here

Perceba que, incrementando apenas em 1 o valor de entrada, passamos a ter o número máximo de combinações sendo 24.
